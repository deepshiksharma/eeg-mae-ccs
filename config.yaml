# masked autoencoder pretraining configuration
pretrain:
  mask_ratio: 0.7
  
  train_epochs: 200
  lr: 1e-4
  batch_size: 64

  data_dir: ""
  validation_split_size: 0.1
  
  output_dir: ""


# classifier fine-tuning configuration
fine-tune:
  pretrained_weights: ""

  train_epochs: 50
  lr_encoder: 1e-6
  lr_classifier: 1e-4
  batch_size: 64

  data_dir: ""
  validation_split_size: 0.1
  test_split_size: 0.2

  output_dir: ""
